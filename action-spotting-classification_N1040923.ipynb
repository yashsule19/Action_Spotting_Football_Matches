{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Coding Steps for Designed Deep Neural Network Model:**\n* Step - 1: Import Libraries.\n* Step - 2: Define the required functions.\n* Step - 3: Dataset Exploration of the pre - extracted features and labels.\n    * Step - 3a : Initalize the required folders to read features and labels for each game.\n    * Step - 3b : Identify the size of each feature array (.npy format) and labels (.json format).\n* Step - 4: Preparation of Dataset.\n    * Step - 4a : Generate the Train, Test and Valid datasets for further using it for implementing different pooling techniques.\n    * Step - 4b : Splitting the datasets into required Inputs and Target.\n* Step - 5: Designing the Deep Learning Model.\n    * Step - 5a : Design a model and implement one by one Pooling techniques : Max Pooling, Average Pooling, Mixed Pooling, NetVLAD pooling.\n    * Step - 5b : After this pooling layer, stack a fully connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n    * Step - 5c : Compile the model and print the model summary.\n    * Step - 5d : Train the model.\n    * Step - 5e : Evaluate the model.\n* Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.\n* Step - 7: Perform prediction of labels from the test features.\n* Step - 8: Calculating important metrics for performance evaluation.\n    * Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.\n* Step - 9: Plotting Confusion matrix, ROC curve, AUC score.\n\n# **Step - 1: Import Libraries**\n\n","metadata":{}},{"cell_type":"code","source":"# For navigating through different folders which are present in the operating system.\nimport os\n\n# For handling json files (In this project, Labels are in json format)\nimport json\n\n# For performing numerical computations\nimport numpy as np\nfrom collections import Counter\n\n# For supressing the output:\nnp.set_printoptions(suppress = True)\n\n# For developing deep learning models\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# For kernal regualizar:\nfrom keras.regularizers import l2\n\n# For visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For measuring the accuracy of the models\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score,f1_score,accuracy_score \nfrom sklearn.metrics import roc_curve, roc_auc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step - 2: Define the required functions.**","metadata":{}},{"cell_type":"code","source":"#For loading pre - extracted C3D features\ndef ReadFeatures_c3d(gamefolder):\n    C3D_1 = np.load(os.path.join(gamefolder,\"1_C3D_PCA512.npy\"))\n    C3D_2 = np.load(os.path.join(gamefolder,\"2_C3D_PCA512.npy\"))\n    \n    return C3D_1, C3D_2\n\n#For loading pre - extracted I3D features\ndef ReadFeatures_i3d(gamefolder):\n    I3D_1 = np.load(os.path.join(gamefolder,\"1_I3D_PCA512.npy\"))\n    I3D_2 = np.load(os.path.join(gamefolder,\"2_I3D_PCA512.npy\"))\n    \n    return I3D_1, I3D_2\n\n#For loading pre - extracted ResNET features\ndef ReadFeatures_resnet(gamefolder):\n    ResNET_1 = np.load(os.path.join(gamefolder,\"1_ResNET_PCA512.npy\"))\n    ResNET_2 = np.load(os.path.join(gamefolder,\"2_ResNET_PCA512.npy\"))\n    \n    return ResNET_1, ResNET_2\n\n#For loading Labels having various annotations \ndef ReadLabels(gamefolder):\n    return json.load(open(os.path.join(gamefolder,\"Labels.json\")))\n\n#For extracting two important annotations Gametime and Label \ndef Extract_gameTime_Label(extracted_labels_json):\n    # Extract the annotations in annotations variable.\n    annotations = extracted_labels_json['annotations']\n\n    # Create an empty list where we can store the extracted values from each key.\n    gameTime = []\n    label = []\n\n    # Develop a for loop to extract gameTime and label from annotations.\n    for annotation in annotations:\n        gameTime.append(annotation['gameTime'])\n        label.append(annotation['label'])\n        \n    return gameTime, label\n\n#For extracting half, minutes and seconds from Gametime\n#Also, assigning new label for a particular frame. \ndef Extract_half_mins_secs(gameTime,dim_label_1half,dim_label_2half):\n    label_1half = np.zeros((dim_label_1half,1))\n    label_2half = np.zeros((dim_label_2half,1))\n\n    for i in range(len(gameTime)):\n        half = gameTime[i][0]\n        mins = gameTime[i][4:6]\n        secs = gameTime[i][7:9]\n        if int(half) == 1:\n            frame_pos1 = ((int(mins) * 120) + (int(secs) * 2)) - 1\n            label_1half[frame_pos1] = 1\n        if int(half) == 2:\n            frame_pos2 = ((int(mins) * 120) + (int(secs) * 2)) - 1\n            label_2half[frame_pos2] = 1\n    \n    return label_1half, label_2half\n\n#For generating one complete game using C3D features\ndef generate_games_c3d(list_games):\n    C3D_1, C3D_2 = ReadFeatures_c3d(list_games)\n    \n    extracted_labels_json = ReadLabels(list_games)\n    gameTime, label = Extract_gameTime_Label(extracted_labels_json)\n    label_1half, label_2half = Extract_half_mins_secs(gameTime,np.shape(C3D_1)[0],np.shape(C3D_2)[0])\n    \n    C3D_1 = np.hstack((C3D_1, label_1half))\n    C3D_2 = np.hstack((C3D_2, label_2half))\n    \n    return np.vstack((C3D_1, C3D_2))\n\n#For generating one complete game using I3D features\ndef generate_games_i3d(list_games):\n    I3D_1, I3D_2 = ReadFeatures_i3d(list_games)\n    \n    extracted_labels_json = ReadLabels(list_games)\n    gameTime, label = Extract_gameTime_Label(extracted_labels_json)\n    label_1half, label_2half = Extract_half_mins_secs(gameTime,np.shape(I3D_1)[0],np.shape(I3D_2)[0])\n    \n    I3D_1 = np.hstack((I3D_1, label_1half))\n    I3D_2 = np.hstack((I3D_2, label_2half))\n    \n    return np.vstack((I3D_1, I3D_2))\n\n#For generating one complete game using ResNET features\ndef generate_games_resnet(list_games):\n    ResNET_1, ResNET_2 = ReadFeatures_resnet(list_games)\n    \n    extracted_labels_json = ReadLabels(list_games)\n    gameTime, label = Extract_gameTime_Label(extracted_labels_json)\n    label_1half, label_2half = Extract_half_mins_secs(gameTime,np.shape(ResNET_1)[0],np.shape(ResNET_2)[0])\n    \n    ResNET_1 = np.hstack((ResNET_1, label_1half))\n    ResNET_2 = np.hstack((ResNET_2, label_2half))\n    \n    return np.vstack((ResNET_1, ResNET_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Link to the Dataset:\n#### Features: https://drive.google.com/drive/folders/1fYtz4rK2gkMTav4_JjZmA0ER42-rV1_s\n#### Labels: https://drive.google.com/drive/folders/1ffjX0QU1MdPArsg-Ejm4ACp_CCa4lmFK","metadata":{}},{"cell_type":"markdown","source":"# **Step - 3: Dataset Exploration of the pre - extracted features and labels.**\n## Step - 3a: Initalize the required folders to read features and labels for each game.","metadata":{}},{"cell_type":"code","source":"Train_folder1 = \"/kaggle/input/england-premier-leauge/Dataset/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\"\nTrain_folder2 = \"/kaggle/input/england-premier-leauge/Dataset/2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal\"\nTrain_folder3 = \"/kaggle/input/england-premier-leauge/Dataset/2015-02-21 - 18-00 Swansea 2 - 1 Manchester United\"\nTrain_folder4 = \"/kaggle/input/england-premier-leauge/Dataset/2015-02-22 - 19-15 Southampton 0 - 2 Liverpool\"\nTest_folder = \"/kaggle/input/england-premier-leauge/Dataset/2015-05-17 - 18-00 Manchester United 1 - 1 Arsenal\"\nValid_folder = \"/kaggle/input/england-premier-leauge/Dataset/2015-04-11 - 19-30 Burnley 0 - 1 Arsenal\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step - 3b: Identify the size of each feature array (.npy format) and labels (.json format).","metadata":{}},{"cell_type":"code","source":"ResNET_1, ResNET_2 = ReadFeatures_resnet(Train_folder1)\nprint(\"For Game 1: (Using ResNET Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C3D_1, C3D_2 = ReadFeatures_c3d(Train_folder1)\nprint(\"For Game 1: (Using C3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(C3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(C3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"I3D_1, I3D_2 = ReadFeatures_i3d(Train_folder1)\nprint(\"For Game 1: (Using I3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(I3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(I3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_labels_json = ReadLabels(Train_folder1)\n# Extract the annotations in annotations variable.\nannotations = extracted_labels_json['annotations']\n\n# Create an empty list where we can store the extracted values from each key.\ngameTime = []\nlabel = []\nprint(\"Labels for Game 1: Information about the actions: \")\nfor annotation in annotations:\n    gameTime = annotation['gameTime']\n    label = annotation['label']\n    print(f\"Game Time: {gameTime} and Label: {label}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNET_1, ResNET_2 = ReadFeatures_resnet(Train_folder2)\nprint(\"For Game 2: (Using ResNET Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C3D_1, C3D_2 = ReadFeatures_c3d(Train_folder2)\nprint(\"For Game 2: (Using C3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(C3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(C3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"I3D_1, I3D_2 = ReadFeatures_i3d(Train_folder2)\nprint(\"For Game 2: (Using I3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(I3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(I3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_labels_json = ReadLabels(Train_folder2)\n# Extract the annotations in annotations variable.\nannotations = extracted_labels_json['annotations']\n\n# Create an empty list where we can store the extracted values from each key.\ngameTime = []\nlabel = []\nprint(\"Labels for Game 2: Information about the actions: \")\nfor annotation in annotations:\n    gameTime = annotation['gameTime']\n    label = annotation['label']\n    print(f\"Game Time: {gameTime} and Label: {label}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNET_1, ResNET_2 = ReadFeatures_resnet(Train_folder3)\nprint(\"For Game 3: (Using ResNET Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C3D_1, C3D_2 = ReadFeatures_c3d(Train_folder3)\nprint(\"For Game 3: (Using C3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(C3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(C3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"I3D_1, I3D_2 = ReadFeatures_i3d(Train_folder3)\nprint(\"For Game 3: (Using I3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(I3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(I3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_labels_json = ReadLabels(Train_folder3)\n# Extract the annotations in annotations variable.\nannotations = extracted_labels_json['annotations']\n\n# Create an empty list where we can store the extracted values from each key.\ngameTime = []\nlabel = []\nprint(\"Labels for Game 3: Information about the actions: \")\nfor annotation in annotations:\n    gameTime = annotation['gameTime']\n    label = annotation['label']\n    print(f\"Game Time: {gameTime} and Label: {label}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNET_1, ResNET_2 = ReadFeatures_resnet(Train_folder4)\nprint(\"For Game 4: (Using ResNET Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C3D_1, C3D_2 = ReadFeatures_c3d(Train_folder4)\nprint(\"For Game 4: (Using C3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(C3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(C3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"I3D_1, I3D_2 = ReadFeatures_i3d(Train_folder4)\nprint(\"For Game 4: (Using I3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(I3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(I3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_labels_json = ReadLabels(Train_folder4)\n# Extract the annotations in annotations variable.\nannotations = extracted_labels_json['annotations']\n\n# Create an empty list where we can store the extracted values from each key.\ngameTime = []\nlabel = []\nprint(\"Labels for Game 4: Information about the actions: \")\nfor annotation in annotations:\n    gameTime = annotation['gameTime']\n    label = annotation['label']\n    print(f\"Game Time: {gameTime} and Label: {label}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNET_1, ResNET_2 = ReadFeatures_resnet(Test_folder)\nprint(\"For Game 5: (Using ResNET Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C3D_1, C3D_2 = ReadFeatures_c3d(Test_folder)\nprint(\"For Game 5: (Using C3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(C3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(C3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"I3D_1, I3D_2 = ReadFeatures_i3d(Test_folder)\nprint(\"For Game 5: (Using I3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(I3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(I3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_labels_json = ReadLabels(Test_folder)\n# Extract the annotations in annotations variable.\nannotations = extracted_labels_json['annotations']\n\n# Create an empty list where we can store the extracted values from each key.\ngameTime = []\nlabel = []\nprint(\"Labels for Game 5: Information about the actions: \")\nfor annotation in annotations:\n    gameTime = annotation['gameTime']\n    label = annotation['label']\n    print(f\"Game Time: {gameTime} and Label: {label}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNET_1, ResNET_2 = ReadFeatures_resnet(Valid_folder)\nprint(\"For Game 6: (Using ResNET Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(ResNET_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C3D_1, C3D_2 = ReadFeatures_c3d(Valid_folder)\nprint(\"For Game 6: (Using C3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(C3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(C3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"I3D_1, I3D_2 = ReadFeatures_i3d(Valid_folder)\nprint(\"For Game 6: (Using I3D Approach)\")\nprint(\"1st Half: (Number of Frames x Number of Features) = \",np.shape(I3D_1))\nprint(\"2nd Half: (Number of Frames x Number of Features) = \",np.shape(I3D_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_labels_json = ReadLabels(Valid_folder)\n# Extract the annotations in annotations variable.\nannotations = extracted_labels_json['annotations']\n\n# Create an empty list where we can store the extracted values from each key.\ngameTime = []\nlabel = []\nprint(\"Labels for Game 6: Information about the actions: \")\nfor annotation in annotations:\n    gameTime = annotation['gameTime']\n    label = annotation['label']\n    print(f\"Game Time: {gameTime} and Label: {label}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Step - 4: Prepration of Datasets (Train, Test and Valid).**\n## Step - 4a: Generate the Train, Test and Valid datasets for further using it for implementing different pooling techniques.\n## Using ResNET Features and Labels","metadata":{}},{"cell_type":"code","source":"Train_game1_resnet = generate_games_resnet(Train_folder1)\nprint(\"For Train Game 1: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game1_resnet))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game2_resnet = generate_games_resnet(Train_folder2)\nprint(\"For Train Game 2: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game2_resnet))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game3_resnet = generate_games_resnet(Train_folder3)\nprint(\"For Train Game 3: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game3_resnet))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game4_resnet = generate_games_resnet(Train_folder4)\nprint(\"For Train Game 4: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game4_resnet))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_games_resnet = np.vstack((Train_game1_resnet, Train_game2_resnet,Train_game3_resnet,Train_game4_resnet))\nprint(\"Train Games: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_games_resnet))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_game_resnet = generate_games_resnet(Test_folder)\nprint(\"Test Game: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Test_game_resnet))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Valid_game_resnet = generate_games_resnet(Valid_folder)\nprint(\"Valid Game: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Valid_game_resnet))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using C3D Features and Labels","metadata":{}},{"cell_type":"code","source":"Train_game1_c3d = generate_games_c3d(Train_folder1)\nprint(\"For Train Game 1: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game1_c3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game2_c3d = generate_games_c3d(Train_folder2)\nprint(\"For Train Game 2: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game2_c3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game3_c3d = generate_games_c3d(Train_folder3)\nprint(\"For Train Game 3: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game3_c3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game4_c3d = generate_games_c3d(Train_folder4)\nprint(\"For Train Game 4: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game4_c3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_games_c3d = np.vstack((Train_game1_c3d, Train_game2_c3d,Train_game3_c3d,Train_game4_c3d))\nprint(\"Train Games: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_games_c3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_game_c3d = generate_games_c3d(Test_folder)\nprint(\"Test Game: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Test_game_c3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Valid_game_c3d = generate_games_c3d(Valid_folder)\nprint(\"Valid Game: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Valid_game_c3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using I3D Features and Labels","metadata":{}},{"cell_type":"code","source":"Train_game1_i3d = generate_games_i3d(Train_folder1)\nprint(\"For Train Game 1: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game1_i3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game2_i3d = generate_games_i3d(Train_folder2)\nprint(\"For Train Game 2: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game2_i3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game3_i3d = generate_games_i3d(Train_folder3)\nprint(\"For Train Game 3: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game3_i3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_game4_i3d = generate_games_i3d(Train_folder4)\nprint(\"For Train Game 4: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_game4_i3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_games_i3d = np.vstack((Train_game1_i3d, Train_game2_i3d,Train_game3_i3d,Train_game4_i3d))\nprint(\"Train Games: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Train_games_i3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_game_i3d = generate_games_i3d(Test_folder)\nprint(\"Test Game: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Test_game_i3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Valid_game_i3d = generate_games_i3d(Valid_folder)\nprint(\"Valid Game: \")\nprint(\"(Total Number of Frames x Number of Features) = \",np.shape(Valid_game_i3d))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step - 4b: Splitting the generate datasets into required Inputs(Features) and Target(Assigned Labels). \n## Using ResNET Approach","metadata":{}},{"cell_type":"code","source":"X_train_resnet = Train_games_resnet[:,0:Train_games_resnet.shape[1] - 1]\nY_train_resnet = Train_games_resnet[:,-1]\nX_test_resnet = Test_game_resnet[:,0:Test_game_resnet.shape[1] - 1]\nY_test_resnet = Test_game_resnet[:,-1]\nX_valid_resnet = Valid_game_resnet[:,0:Valid_game_resnet.shape[1] - 1]\nY_valid_resnet = Valid_game_resnet[:,-1]\n\nprint(\"Using ResNET Approach\")\nprint(\"X_train = \",np.shape(X_train_resnet))\nprint(\"Y_train = \",np.shape(Y_train_resnet))\nprint(\"X_test = \",np.shape(X_test_resnet))\nprint(\"Y_test = \",np.shape(Y_test_resnet))\nprint(\"X_valid = \",np.shape(X_valid_resnet))\nprint(\"Y_valid = \",np.shape(Y_valid_resnet))\nprint(\"Count of Action Labels\")\nprint(\"Y_train labels: {}\".format(Counter(Y_train_resnet)))\nprint(\"Y_test labels: {}\".format(Counter(Y_test_resnet)))\nprint(\"Y_valid labels: {} \".format(Counter(Y_valid_resnet)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using C3D Approach","metadata":{}},{"cell_type":"code","source":"X_train_c3d = Train_games_c3d[:,0:Train_games_c3d.shape[1] - 1]\nY_train_c3d = Train_games_c3d[:,-1]\nX_test_c3d = Test_game_c3d[:,0:Test_game_c3d.shape[1] - 1]\nY_test_c3d = Test_game_c3d[:,-1]\nX_valid_c3d = Valid_game_c3d[:,0:Valid_game_c3d.shape[1] - 1]\nY_valid_c3d = Valid_game_c3d[:,-1]\n\nprint(\"Using C3D Approach\")\nprint(\"X_train = \",np.shape(X_train_c3d))\nprint(\"Y_train = \",np.shape(Y_train_c3d))\nprint(\"X_test = \",np.shape(X_test_c3d))\nprint(\"Y_test = \",np.shape(Y_test_c3d))\nprint(\"X_valid = \",np.shape(X_valid_c3d))\nprint(\"Y_valid = \",np.shape(Y_valid_c3d))\nprint(\"Count of Action Labels\")\nprint(\"Y_train labels: {}\".format(Counter(Y_train_c3d)))\nprint(\"Y_test labels: {}\".format(Counter(Y_test_c3d)))\nprint(\"Y_valid labels: {}\".format(Counter(Y_valid_c3d)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using I3D Approach ","metadata":{}},{"cell_type":"code","source":"X_train_i3d = Train_games_i3d[:,0:Train_games_i3d.shape[1] - 1]\nY_train_i3d = Train_games_i3d[:,-1]\nX_test_i3d = Test_game_i3d[:,0:Test_game_i3d.shape[1] - 1]\nY_test_i3d = Test_game_i3d[:,-1]\nX_valid_i3d = Valid_game_i3d[:,0:Valid_game_i3d.shape[1] - 1]\nY_valid_i3d = Valid_game_i3d[:,-1]\n\nprint(\"Using I3D Approach\")\nprint(\"X_train = \",np.shape(X_train_i3d))\nprint(\"Y_train = \",np.shape(Y_train_i3d))\nprint(\"X_test = \",np.shape(X_test_i3d))\nprint(\"Y_test = \",np.shape(Y_test_i3d))\nprint(\"X_valid = \",np.shape(X_valid_i3d))\nprint(\"Y_valid = \",np.shape(Y_valid_i3d))\nprint(\"Count of Action Labels\")\nprint(\"Y_train labels: {}\".format(Counter(Y_train_i3d)))\nprint(\"Y_test labels: {}\".format(Counter(Y_test_i3d)))\nprint(\"Y_valid labels: {}\".format(Counter(Y_valid_i3d)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using ResNET Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Max Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_max_resnet = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Max-Pool1D_ResNET')\n\n# Add a reshaping layer\nmodel_max_resnet.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Max Pooling 1D:\nmodel_max_resnet.add(keras.layers.MaxPool1D(pool_size = 2,strides = 1,padding = \"same\", name = 'Max-Pool1D-Layer'))\n\n# Flattening the pooled features\nmodel_max_resnet.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_max_resnet.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_max_resnet.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_max_resnet.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_max_resnet.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_max_resnet.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_max_resnet.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_max_resnet.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_max_resnet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_max_resnet,to_file='model_max_resnet.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_resnet = tf.reshape(X_train_resnet, [X_train_resnet.shape[0], 1, X_train_resnet.shape[1]])\nX_valid_reshape_resnet = tf.reshape(X_valid_resnet, [X_valid_resnet.shape[0], 1, X_valid_resnet.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_max_resnet = model_max_resnet.fit(X_train_reshape_resnet,\n          Y_train_resnet,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_resnet, Y_valid_resnet),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using ResNET Approach - Max Pooling) :\\n------------------------------------\")\nX_test_reshape_resnet = tf.reshape(X_test_resnet, [X_test_resnet.shape[0], 1,X_test_resnet.shape[1]])\nmodel_max_resnet.evaluate(X_test_reshape_resnet,Y_test_resnet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_max_resnet.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_max_resnet.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using ResNET Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_max_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_max_resnet.history['loss'],'r-o', label = 'train')\nplt.plot(history_max_resnet.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using ResNET Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_max_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_resnet_maxpool = model_max_resnet.predict(X_test_resnet)\nY_pred_resnet_maxpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_resnet_maxpool_round2 = Y_pred_resnet_maxpool.round(decimals=2)\nY_pred_resnet_maxpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_resnet_maxpool_round0 = Y_pred_resnet_maxpool.round(decimals=0)\nY_pred_resnet_maxpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using ResNET Approach - Max Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_resnet, Y_pred_resnet_maxpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_resnet, Y_pred_resnet_maxpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_resnet, Y_pred_resnet_maxpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_resnet, Y_pred_resnet_maxpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_resnet, Y_pred_resnet_maxpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_resnet, Y_pred_resnet_maxpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_resnet_maxpool = confusion_matrix(Y_test_resnet, Y_pred_resnet_maxpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_resnet_maxpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using ResNET Approach - Max Pooling\", loc='center')\nplt.savefig(\"cm_max_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_resnet_maxpool, tpr_resnet_maxpool, tr_resnet_max = roc_curve(Y_test_resnet, np.array(Y_pred_resnet_maxpool_round2))\nauc_resnet_maxpool = roc_auc_score(Y_test_resnet, Y_pred_resnet_maxpool_round2)\n\nplt.plot(fpr_resnet_maxpool, tpr_resnet_maxpool, 'b-o', label = 'AUC = %0.4f'%auc_resnet_maxpool)\nplt.plot(fpr_resnet_maxpool,fpr_resnet_maxpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using ResNET Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_max_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using C3D Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Max Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_max_c3d = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Max-Pool1D_C3D')\n\n# Add a reshaping layer\nmodel_max_c3d.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Max Pooling 1D:\nmodel_max_c3d.add(keras.layers.MaxPool1D(pool_size = 2,strides = 1,padding = \"same\", name = 'Max-Pool1D-Layer'))\n\n# Flattening the pooled features\nmodel_max_c3d.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_max_c3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_max_c3d.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_max_c3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_max_c3d.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_max_c3d.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_max_c3d.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_max_c3d.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_max_c3d.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_max_c3d,to_file='model_max_c3d.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_c3d = tf.reshape(X_train_c3d, [X_train_c3d.shape[0], 1, X_train_c3d.shape[1]])\nX_valid_reshape_c3d = tf.reshape(X_valid_c3d, [X_valid_c3d.shape[0], 1, X_valid_c3d.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_max_c3d = model_max_c3d.fit(X_train_reshape_c3d,\n          Y_train_c3d,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_c3d, Y_valid_c3d),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using C3D Approach - Max Pooling) :\\n------------------------------------\")\nX_test_reshape_c3d = tf.reshape(X_test_c3d, [X_test_c3d.shape[0], 1,X_test_c3d.shape[1]])\nmodel_max_c3d.evaluate(X_test_reshape_c3d,Y_test_c3d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_max_c3d.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_max_c3d.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using C3D Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_max_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_max_c3d.history['loss'],'r-o', label = 'train')\nplt.plot(history_max_c3d.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using C3D Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_max_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_c3d_maxpool = model_max_c3d.predict(X_test_c3d)\nY_pred_c3d_maxpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_c3d_maxpool_round2 = Y_pred_c3d_maxpool.round(decimals=2)\nY_pred_c3d_maxpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_c3d_maxpool_round0 = Y_pred_c3d_maxpool.round(decimals=0)\nY_pred_c3d_maxpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using C3D Approach - Max Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_c3d, Y_pred_c3d_maxpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_c3d, Y_pred_c3d_maxpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_c3d, Y_pred_c3d_maxpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_c3d, Y_pred_c3d_maxpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_c3d, Y_pred_c3d_maxpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_c3d, Y_pred_c3d_maxpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_c3d_maxpool = confusion_matrix(Y_test_c3d, Y_pred_c3d_maxpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_c3d_maxpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using C3D Approach - Max Pooling\", loc='center')\nplt.savefig(\"cm_max_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_c3d_maxpool, tpr_c3d_maxpool, tr_c3d_max = roc_curve(Y_test_c3d, np.array(Y_pred_c3d_maxpool_round2))\nauc_c3d_maxpool = roc_auc_score(Y_test_c3d, Y_pred_c3d_maxpool_round2)\n\nplt.plot(fpr_c3d_maxpool, tpr_c3d_maxpool, 'b-o', label = 'AUC = %0.4f'%auc_c3d_maxpool)\nplt.plot(fpr_c3d_maxpool,fpr_c3d_maxpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using C3D Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_max_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using I3D Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Max Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_max_i3d = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Max-Pool1D_I3D')\n\n# Add a reshaping layer\nmodel_max_i3d.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Max Pooling 1D:\nmodel_max_i3d.add(keras.layers.MaxPool1D(pool_size = 2,strides = 1,padding = \"same\", name = 'Max-Pool1D-Layer'))\n\n# Flattening the pooled features\nmodel_max_i3d.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_max_i3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_max_i3d.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_max_i3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_max_i3d.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_max_i3d.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_max_i3d.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_max_i3d.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_max_i3d.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_max_i3d,to_file='model_max_i3d.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_i3d = tf.reshape(X_train_i3d, [X_train_i3d.shape[0], 1, X_train_i3d.shape[1]])\nX_valid_reshape_i3d = tf.reshape(X_valid_i3d, [X_valid_i3d.shape[0], 1, X_valid_i3d.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_max_i3d = model_max_i3d.fit(X_train_reshape_i3d,\n          Y_train_i3d,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_i3d, Y_valid_i3d),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using I3D Approach - Max Pooling) :\\n------------------------------------\")\nX_test_reshape_i3d = tf.reshape(X_test_i3d, [X_test_i3d.shape[0], 1,X_test_i3d.shape[1]])\nmodel_max_i3d.evaluate(X_test_reshape_i3d,Y_test_i3d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_max_i3d.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_max_i3d.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using I3D Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_max_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_max_i3d.history['loss'],'r-o', label = 'train')\nplt.plot(history_max_i3d.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using I3D Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_max_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_i3d_maxpool = model_max_i3d.predict(X_test_i3d)\nY_pred_i3d_maxpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_i3d_maxpool_round2 = Y_pred_i3d_maxpool.round(decimals=2)\nY_pred_i3d_maxpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_i3d_maxpool_round0 = Y_pred_i3d_maxpool.round(decimals=0)\nY_pred_i3d_maxpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using I3D Approach - Max Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_i3d, Y_pred_i3d_maxpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_i3d, Y_pred_i3d_maxpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_i3d, Y_pred_i3d_maxpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_i3d, Y_pred_i3d_maxpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_i3d, Y_pred_i3d_maxpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_i3d, Y_pred_i3d_maxpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_i3d_maxpool = confusion_matrix(Y_test_i3d, Y_pred_i3d_maxpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_i3d_maxpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using I3D Approach - Max Pooling\", loc='center')\nplt.savefig(\"cm_max_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_i3d_maxpool, tpr_i3d_maxpool, tr_i3d_max = roc_curve(Y_test_i3d, np.array(Y_pred_i3d_maxpool_round2))\nauc_i3d_maxpool = roc_auc_score(Y_test_i3d, Y_pred_i3d_maxpool_round2)\n\nplt.plot(fpr_i3d_maxpool, tpr_i3d_maxpool, 'b-o', label = 'AUC = %0.4f'%auc_i3d_maxpool)\nplt.plot(fpr_i3d_maxpool,fpr_i3d_maxpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using I3D Approach - Max Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_max_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using ResNET Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Average Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_avg_resnet = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Average-Pool1D_ResNET')\n\n# Add a reshaping layer\nmodel_avg_resnet.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Max Pooling 1D:\nmodel_avg_resnet.add(keras.layers.AveragePooling1D(pool_size = 2,strides = 1,padding = \"same\", name = 'Average-Pool1D-Layer'))\n\n# Flattening the pooled features\nmodel_avg_resnet.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_avg_resnet.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_avg_resnet.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_avg_resnet.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_avg_resnet.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_avg_resnet.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_avg_resnet.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_avg_resnet.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_avg_resnet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_avg_resnet,to_file='model_avg_resnet.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_resnet = tf.reshape(X_train_resnet, [X_train_resnet.shape[0], 1, X_train_resnet.shape[1]])\nX_valid_reshape_resnet = tf.reshape(X_valid_resnet, [X_valid_resnet.shape[0], 1, X_valid_resnet.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_avg_resnet = model_avg_resnet.fit(X_train_reshape_resnet,\n          Y_train_resnet,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_resnet, Y_valid_resnet),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using ResNET Approach - Average Pooling) :\\n------------------------------------\")\nX_test_reshape_resnet = tf.reshape(X_test_resnet, [X_test_resnet.shape[0], 1,X_test_resnet.shape[1]])\nmodel_avg_resnet.evaluate(X_test_reshape_resnet,Y_test_resnet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_avg_resnet.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_avg_resnet.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using ResNET Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_avg_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_avg_resnet.history['loss'],'r-o', label = 'train')\nplt.plot(history_avg_resnet.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using ResNET Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_avg_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_resnet_avgpool = model_avg_resnet.predict(X_test_resnet)\nY_pred_resnet_avgpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_resnet_avgpool_round2 = Y_pred_resnet_avgpool.round(decimals=2)\nY_pred_resnet_avgpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_resnet_avgpool_round0 = Y_pred_resnet_avgpool.round(decimals=0)\nY_pred_resnet_avgpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using ResNET Approach - Average Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_resnet, Y_pred_resnet_avgpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_resnet, Y_pred_resnet_avgpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_resnet, Y_pred_resnet_avgpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_resnet, Y_pred_resnet_avgpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_resnet, Y_pred_resnet_avgpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_resnet, Y_pred_resnet_avgpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_resnet_avgpool = confusion_matrix(Y_test_resnet, Y_pred_resnet_avgpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_resnet_avgpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using ResNET Approach - Average Pooling\", loc='center')\nplt.savefig(\"cm_avg_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_resnet_avgpool, tpr_resnet_avgpool, tr_resnet_avg = roc_curve(Y_test_resnet, np.array(Y_pred_resnet_avgpool_round2))\nauc_resnet_avgpool = roc_auc_score(Y_test_resnet, Y_pred_resnet_avgpool_round2)\n\nplt.plot(fpr_resnet_avgpool, tpr_resnet_avgpool, 'b-o', label = 'AUC = %0.4f'%auc_resnet_avgpool)\nplt.plot(fpr_resnet_avgpool,fpr_resnet_avgpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using ResNET Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_avg_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using C3D Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Average Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_avg_c3d = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Average-Pool1D_C3D')\n\n# Add a reshaping layer\nmodel_avg_c3d.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Max Pooling 1D:\nmodel_avg_c3d.add(keras.layers.AveragePooling1D(pool_size = 2,strides = 1,padding = \"same\", name = 'Average-Pool1D-Layer'))\n\n# Flattening the pooled features\nmodel_avg_c3d.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_avg_c3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_avg_c3d.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_avg_c3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_avg_c3d.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_avg_c3d.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_avg_c3d.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_avg_c3d.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_avg_c3d.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_avg_c3d,to_file='model_avg_c3d.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_c3d = tf.reshape(X_train_c3d, [X_train_c3d.shape[0], 1, X_train_c3d.shape[1]])\nX_valid_reshape_c3d = tf.reshape(X_valid_c3d, [X_valid_c3d.shape[0], 1, X_valid_c3d.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_avg_c3d = model_avg_c3d.fit(X_train_reshape_c3d,\n          Y_train_c3d,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_c3d, Y_valid_c3d),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using C3D Approach - Average Pooling) :\\n------------------------------------\")\nX_test_reshape_c3d = tf.reshape(X_test_c3d, [X_test_c3d.shape[0], 1,X_test_c3d.shape[1]])\nmodel_avg_c3d.evaluate(X_test_reshape_c3d,Y_test_c3d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_avg_c3d.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_avg_c3d.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using C3D Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_avg_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_avg_c3d.history['loss'],'r-o', label = 'train')\nplt.plot(history_avg_c3d.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using C3D Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_avg_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_c3d_avgpool = model_avg_c3d.predict(X_test_c3d)\nY_pred_c3d_avgpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_c3d_avgpool_round2 = Y_pred_c3d_avgpool.round(decimals=2)\nY_pred_c3d_avgpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_c3d_avgpool_round0 = Y_pred_c3d_avgpool.round(decimals=0)\nY_pred_c3d_avgpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using C3D Approach - Average Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_c3d, Y_pred_c3d_avgpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_c3d, Y_pred_c3d_avgpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_c3d, Y_pred_c3d_avgpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_c3d, Y_pred_c3d_avgpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_c3d, Y_pred_c3d_avgpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_c3d, Y_pred_c3d_avgpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_c3d_avgpool = confusion_matrix(Y_test_c3d, Y_pred_c3d_avgpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_c3d_avgpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using C3D Approach - Average Pooling\", loc='center')\nplt.savefig(\"cm_avg_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_c3d_avgpool, tpr_c3d_avgpool, tr_c3d_avg = roc_curve(Y_test_c3d, np.array(Y_pred_c3d_avgpool_round2))\nauc_c3d_avgpool = roc_auc_score(Y_test_c3d, Y_pred_c3d_avgpool_round2)\n\nplt.plot(fpr_c3d_avgpool, tpr_c3d_avgpool, 'b-o', label = 'AUC = %0.4f'%auc_c3d_avgpool)\nplt.plot(fpr_c3d_avgpool,fpr_c3d_avgpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using C3D Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_avg_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using I3D Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Average Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_avg_i3d = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Average-Pool1D_I3D')\n\n# Add a reshaping layer\nmodel_avg_i3d.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Max Pooling 1D:\nmodel_avg_i3d.add(keras.layers.AveragePooling1D(pool_size = 2,strides = 1,padding = \"same\", name = 'Average-Pool1D-Layer'))\n\n# Flattening the pooled features\nmodel_avg_i3d.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_avg_i3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_avg_i3d.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_avg_i3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_avg_i3d.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_avg_i3d.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_avg_i3d.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_avg_i3d.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_avg_i3d.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_avg_i3d,to_file='model_avg_i3d.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_i3d = tf.reshape(X_train_i3d, [X_train_i3d.shape[0], 1, X_train_i3d.shape[1]])\nX_valid_reshape_i3d = tf.reshape(X_valid_i3d, [X_valid_i3d.shape[0], 1, X_valid_i3d.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_avg_i3d = model_avg_i3d.fit(X_train_reshape_i3d,\n          Y_train_i3d,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_i3d, Y_valid_i3d),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using I3D Approach - Average Pooling) :\\n------------------------------------\")\nX_test_reshape_i3d = tf.reshape(X_test_i3d, [X_test_i3d.shape[0], 1,X_test_i3d.shape[1]])\nmodel_avg_i3d.evaluate(X_test_reshape_i3d,Y_test_i3d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_avg_i3d.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_avg_i3d.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using I3D Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_avg_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_avg_i3d.history['loss'],'r-o', label = 'train')\nplt.plot(history_avg_i3d.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using I3D Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_avg_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_i3d_avgpool = model_avg_i3d.predict(X_test_i3d)\nY_pred_i3d_avgpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_i3d_avgpool_round2 = Y_pred_i3d_avgpool.round(decimals=2)\nY_pred_i3d_avgpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_i3d_avgpool_round0 = Y_pred_i3d_avgpool.round(decimals=0)\nY_pred_i3d_avgpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using I3D Approach - Average Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_i3d, Y_pred_i3d_avgpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_i3d, Y_pred_i3d_avgpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_i3d, Y_pred_i3d_avgpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_i3d, Y_pred_i3d_avgpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_i3d, Y_pred_i3d_avgpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_i3d, Y_pred_i3d_avgpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_i3d_avgpool = confusion_matrix(Y_test_i3d, Y_pred_i3d_avgpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_i3d_avgpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using I3D Approach - Average Pooling\", loc='center')\nplt.savefig(\"cm_avg_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_i3d_avgpool, tpr_i3d_avgpool, tr_i3d_avg = roc_curve(Y_test_i3d, np.array(Y_pred_i3d_avgpool_round2))\nauc_i3d_avgpool = roc_auc_score(Y_test_i3d, Y_pred_i3d_avgpool_round2)\n\nplt.plot(fpr_i3d_avgpool, tpr_i3d_avgpool, 'b-o', label = 'AUC = %0.4f'%auc_i3d_avgpool)\nplt.plot(fpr_i3d_avgpool,fpr_i3d_avgpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using I3D Approach - Average Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_avg_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define mixed max-average pooling layer\nclass MixedPooling(tf.keras.layers.Layer):\n    def __init__(self, alpha, size=2, name = 'Mixed-Pool1D-Layer'):\n        super(MixedPooling, self).__init__(name = name)\n        self.alpha = self.add_weight(shape = (),dtype=tf.float32, initializer=tf.keras.initializers.Constant(alpha))\n        self.max_pool = tf.keras.layers.MaxPooling1D(pool_size=size, strides=1, padding='same')\n        self.avg_pool = tf.keras.layers.AveragePooling1D(pool_size=size, strides=1, padding='same')\n\n    def call(self, inputs):\n        x1 = self.max_pool(inputs)\n        x2 = self.avg_pool(inputs)\n        outputs = tf.add(tf.multiply(x1, self.alpha), tf.multiply(x2, (1-self.alpha)))\n        return outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using ResNET Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Mixed Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_mix_resnet = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Mixed-Pool1D_ResNET')\n\n# Add a reshaping layer\nmodel_mix_resnet.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Mixed Pooling (MaxPool1D and AveragePool1D)\nmodel_mix_resnet.add(MixedPooling(alpha=0.7, size=2))\n\n# Flattening the pooled features\nmodel_mix_resnet.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_mix_resnet.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_mix_resnet.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_mix_resnet.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_mix_resnet.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_mix_resnet.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_mix_resnet.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_mix_resnet.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_mix_resnet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_mix_resnet,to_file='model_mix_resnet.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_resnet = tf.reshape(X_train_resnet, [X_train_resnet.shape[0], 1, X_train_resnet.shape[1]])\nX_valid_reshape_resnet = tf.reshape(X_valid_resnet, [X_valid_resnet.shape[0], 1, X_valid_resnet.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_mix_resnet = model_mix_resnet.fit(X_train_reshape_resnet,\n          Y_train_resnet,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_resnet, Y_valid_resnet),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using ResNET Approach - Mixed Pooling) :\\n------------------------------------\")\nX_test_reshape_resnet = tf.reshape(X_test_resnet, [X_test_resnet.shape[0], 1,X_test_resnet.shape[1]])\nmodel_mix_resnet.evaluate(X_test_reshape_resnet,Y_test_resnet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_mix_resnet.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_mix_resnet.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using ResNET Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_mix_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_mix_resnet.history['loss'],'r-o', label = 'train')\nplt.plot(history_mix_resnet.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using ResNET Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_mix_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_resnet_mixpool = model_mix_resnet.predict(X_test_resnet)\nY_pred_resnet_mixpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_resnet_mixpool_round2 = Y_pred_resnet_mixpool.round(decimals=2)\nY_pred_resnet_mixpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_resnet_mixpool_round0 = Y_pred_resnet_mixpool.round(decimals=0)\nY_pred_resnet_mixpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using ResNET Approach - Mixed Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_resnet, Y_pred_resnet_mixpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_resnet, Y_pred_resnet_mixpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_resnet, Y_pred_resnet_mixpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_resnet, Y_pred_resnet_mixpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_resnet, Y_pred_resnet_mixpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_resnet, Y_pred_resnet_mixpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_resnet_mixpool = confusion_matrix(Y_test_resnet, Y_pred_resnet_mixpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_resnet_mixpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using ResNET Approach - Mixed Pooling\", loc='center')\nplt.savefig(\"cm_mix_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_resnet_mixpool, tpr_resnet_mixpool, tr_resnet_mix = roc_curve(Y_test_resnet, np.array(Y_pred_resnet_mixpool_round2))\nauc_resnet_mixpool = roc_auc_score(Y_test_resnet, Y_pred_resnet_mixpool_round2)\n\nplt.plot(fpr_resnet_mixpool, tpr_resnet_mixpool, 'b-o', label = 'AUC = %0.4f'%auc_resnet_mixpool)\nplt.plot(fpr_resnet_mixpool,fpr_resnet_mixpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using ResNET Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_mix_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using C3D Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Mixed Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_mix_c3d = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Mixed-Pool1D_C3D')\n\n# Add a reshaping layer\nmodel_mix_c3d.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Mixed Pooling (MaxPool1D and AveragePool1D)\nmodel_mix_c3d.add(MixedPooling(alpha=0.7, size=2))\n\n# Flattening the pooled features\nmodel_mix_c3d.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_mix_c3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_mix_c3d.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_mix_c3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_mix_c3d.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_mix_c3d.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_mix_c3d.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_mix_c3d.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_mix_c3d.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_mix_c3d,to_file='model_mix_c3d.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_c3d = tf.reshape(X_train_c3d, [X_train_c3d.shape[0], 1, X_train_c3d.shape[1]])\nX_valid_reshape_c3d = tf.reshape(X_valid_c3d, [X_valid_c3d.shape[0], 1, X_valid_c3d.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_mix_c3d = model_mix_c3d.fit(X_train_reshape_c3d,\n          Y_train_c3d,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_c3d, Y_valid_c3d),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using C3D Approach - Mixed Pooling) :\\n------------------------------------\")\nX_test_reshape_c3d = tf.reshape(X_test_c3d, [X_test_c3d.shape[0], 1,X_test_c3d.shape[1]])\nmodel_mix_c3d.evaluate(X_test_reshape_c3d,Y_test_c3d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_mix_c3d.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_mix_c3d.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using C3D Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_mix_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_mix_c3d.history['loss'],'r-o', label = 'train')\nplt.plot(history_mix_c3d.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using C3D Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_mix_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_c3d_mixpool = model_mix_c3d.predict(X_test_c3d)\nY_pred_c3d_mixpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_c3d_mixpool_round2 = Y_pred_c3d_mixpool.round(decimals=2)\nY_pred_c3d_mixpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_c3d_mixpool_round0 = Y_pred_c3d_mixpool.round(decimals=0)\nY_pred_c3d_mixpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using C3D Approach - Mixed Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_c3d, Y_pred_c3d_mixpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_c3d, Y_pred_c3d_mixpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_c3d, Y_pred_c3d_mixpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_c3d, Y_pred_c3d_mixpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_c3d, Y_pred_c3d_mixpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_c3d, Y_pred_c3d_mixpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_c3d_mixpool = confusion_matrix(Y_test_c3d, Y_pred_c3d_mixpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_c3d_mixpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using C3D Approach - Mixed Pooling\", loc='center')\nplt.savefig(\"cm_mix_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_c3d_mixpool, tpr_c3d_mixpool, tr_c3d_mix = roc_curve(Y_test_c3d, np.array(Y_pred_c3d_mixpool_round2))\nauc_c3d_mixpool = roc_auc_score(Y_test_c3d, Y_pred_c3d_mixpool_round2)\n\nplt.plot(fpr_c3d_mixpool, tpr_c3d_mixpool, 'b-o', label = 'AUC = %0.4f'%auc_c3d_mixpool)\nplt.plot(fpr_c3d_mixpool,fpr_c3d_mixpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using C3D Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_mix_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using I3D Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs Mixed Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_mix_i3d = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_Mixed-Pool1D_I3D')\n\n# Add a reshaping layer\nmodel_mix_i3d.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using Mixed Pooling (MaxPool1D and AveragePool1D)\nmodel_mix_i3d.add(MixedPooling(alpha=0.7, size=2))\n\n# Flattening the pooled features\nmodel_mix_i3d.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_mix_i3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_mix_i3d.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_mix_i3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_mix_i3d.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_mix_i3d.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_mix_i3d.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_mix_i3d.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_mix_i3d.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_mix_i3d,to_file='model_mix_i3d.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_i3d = tf.reshape(X_train_i3d, [X_train_i3d.shape[0], 1, X_train_i3d.shape[1]])\nX_valid_reshape_i3d = tf.reshape(X_valid_i3d, [X_valid_i3d.shape[0], 1, X_valid_i3d.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_mix_i3d = model_mix_i3d.fit(X_train_reshape_i3d,\n          Y_train_i3d,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_i3d, Y_valid_i3d),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using I3D Approach - Mixed Pooling) :\\n------------------------------------\")\nX_test_reshape_i3d = tf.reshape(X_test_i3d, [X_test_i3d.shape[0], 1,X_test_i3d.shape[1]])\nmodel_mix_i3d.evaluate(X_test_reshape_i3d,Y_test_i3d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_mix_i3d.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_mix_i3d.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using I3D Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_mix_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_mix_i3d.history['loss'],'r-o', label = 'train')\nplt.plot(history_mix_i3d.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using I3D Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_mix_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_i3d_mixpool = model_mix_i3d.predict(X_test_i3d)\nY_pred_i3d_mixpool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_i3d_mixpool_round2 = Y_pred_i3d_mixpool.round(decimals=2)\nY_pred_i3d_mixpool_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_i3d_mixpool_round0 = Y_pred_i3d_mixpool.round(decimals=0)\nY_pred_i3d_mixpool_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using I3D Approach - Mixed Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_i3d, Y_pred_i3d_mixpool_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_i3d, Y_pred_i3d_mixpool_round0))\nprint('Precision Score : ',(precision_score(Y_test_i3d, Y_pred_i3d_mixpool_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_i3d, Y_pred_i3d_mixpool_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_i3d, Y_pred_i3d_mixpool_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_i3d, Y_pred_i3d_mixpool_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_i3d_mixpool = confusion_matrix(Y_test_i3d, Y_pred_i3d_mixpool_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_i3d_mixpool, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using I3D Approach - Mixed Pooling\", loc='center')\nplt.savefig(\"cm_mix_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_i3d_mixpool, tpr_i3d_mixpool, tr_i3d_mix = roc_curve(Y_test_i3d, np.array(Y_pred_i3d_mixpool_round2))\nauc_i3d_mixpool = roc_auc_score(Y_test_i3d, Y_pred_i3d_mixpool_round2)\n\nplt.plot(fpr_i3d_mixpool, tpr_i3d_mixpool, 'b-o', label = 'AUC = %0.4f'%auc_i3d_mixpool)\nplt.plot(fpr_i3d_mixpool,fpr_i3d_mixpool,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using I3D Approach - Mixed Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_mix_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define NetVLAD Pooling\n\nimport tensorflow as tf\nimport math\nimport numpy as np\n\nclass PoolingBaseModel:\n    \"\"\"Inherit from this class when implementing new models.\"\"\"\n\n    def __init__(self, feature_size, max_samples, cluster_size, output_dim,\n                 gating=True, add_batch_norm=True, is_training=True):\n        \"\"\"Initialize a NetVLAD block.\n\n        Args:\n            feature_size: Dimensionality of the input features.\n            max_samples: The maximum number of samples to pool.\n            cluster_size: The number of clusters.\n            output_dim: size of the output space after dimension reduction.\n            add_batch_norm: (bool) if True, adds batch normalization.\n            is_training: (bool) Whether or not the graph is training.\n        \"\"\"\n\n        self.feature_size = feature_size\n        self.max_samples = max_samples\n        self.output_dim = output_dim\n        self.is_training = is_training\n        self.gating = gating\n        self.add_batch_norm = add_batch_norm\n        self.cluster_size = cluster_size\n\n    def forward(self, reshaped_input):\n        raise NotImplementedError(\"Models should implement the forward pass.\")\n        \n    def context_gating(self, input_layer):\n        \"\"\"Context Gating\n\n        Args:\n            input_layer: Input layer in the following shape:\n            'batch_size' x 'number_of_activation'\n\n        Returns:\n            activation: gated layer in the following shape:\n            'batch_size' x 'number_of_activation'\n        \"\"\"\n\n        input_dim = input_layer.shape[1]\n\n        gating_weights = tf.Variable(name=\"gating_weights\",\n                                     shape=[input_dim, input_dim],\n                                     initializer=tf.random_normal_initializer(\n                                         stddev=1 / math.sqrt(input_dim)))\n\n        gates = tf.matmul(input_layer, gating_weights)\n\n        if self.add_batch_norm:\n            gates = layers.BatchNormalization()(gates, training=self.is_training, name=\"gating_bn\")\n        else:\n            gating_biases = tf.Variable(name=\"gating_biases\",\n                                        shape=[input_dim],\n                                        initializer=tf.random_normal_initializer(\n                                            stddev=1 / math.sqrt(input_dim)))\n            gates += gating_biases\n\n        gates = tf.sigmoid(gates)\n\n        activation = tf.multiply(input_layer, gates)\n\n        return activation    \n    \n\n#class NetVLAD(PoolingBaseModel):\nclass NetVLAD(tf.keras.Model):\n    \"\"\"Creates a NetVLAD class.\n    \"\"\"\n    def __init__(self, feature_size, max_samples, cluster_size, output_dim,\n                 gating=True, add_batch_norm=True, is_training=True):\n        #super(PoolingBaseModel, self).__init__()\n        super(NetVLAD, self).__init__()\n        self.feature_size = feature_size\n        self.max_samples = max_samples\n        self.cluster_size = cluster_size\n        self.output_dim = output_dim\n        self.gating = gating\n        self.add_batch_norm = add_batch_norm\n        self.is_training = is_training\n\n        self.cluster_weights = tf.Variable(tf.random.normal(\n            shape=[self.feature_size, self.cluster_size],\n            stddev=1 / math.sqrt(self.feature_size)),\n            name=\"cluster_weights\")\n\n        if not add_batch_norm:\n            self.cluster_biases = tf.Variable(tf.random.normal(\n                shape=[self.cluster_size],\n                stddev=1 / math.sqrt(self.feature_size)),\n                name=\"cluster_biases\")\n\n        self.cluster_weights2 = tf.Variable(tf.random.normal(\n            shape=[1, self.feature_size, self.cluster_size],\n            stddev=1 / math.sqrt(self.feature_size)),\n            name=\"cluster_weights2\")\n\n        self.hidden1_weights = tf.Variable(tf.random.normal(\n            shape=[self.cluster_size * self.feature_size, self.output_dim],\n            stddev=1 / math.sqrt(self.cluster_size)),\n            name=\"hidden1_weights\")\n    \n    def call(self, inputs):\n        \"\"\"Forward pass of a NetVLAD block.\n\n        Args:\n        inputs: If your input is in that form:\n        'batch_size' x 'max_samples' x 'feature_size'\n        It should be reshaped in the following form:\n        'batch_size*max_samples' x 'feature_size'\n        by performing:\n        inputs = tf.reshape(input, [-1, feature_size])\n\n        Returns:\n        vlad: the pooled vector of size: 'batch_size' x 'output_dim'\n        \"\"\"\n        reshaped_input = tf.reshape(inputs, [-1, self.feature_size])\n\n        activation = tf.matmul(reshaped_input, self.cluster_weights)\n\n        if self.add_batch_norm:\n            activation = tf.keras.layers.BatchNormalization(\n                name=\"cluster_bn\")(activation, training=self.is_training)\n        else:\n            activation += self.cluster_biases\n\n        activation = tf.nn.softmax(activation)\n\n        activation = tf.reshape(activation,\n                                [-1, self.max_samples, self.cluster_size])\n\n        a_sum = tf.reduce_sum(activation, axis=-2, keepdims=True)\n\n        a = tf.multiply(a_sum, self.cluster_weights2)\n\n        activation = tf.transpose(activation, perm=[0, 2, 1])\n\n        reshaped_input = tf.reshape(reshaped_input, [-1,\n                                                     self.max_samples, self.feature_size])\n\n        vlad = tf.matmul(activation, reshaped_input)\n        vlad = tf.transpose(vlad, perm=[0, 2, 1])\n        vlad = tf.subtract(vlad, a)\n\n        vlad = tf.nn.l2_normalize(vlad, axis=1)\n\n        vlad = tf.reshape(vlad, [-1, self.cluster_size * self.feature_size])\n        vlad = tf.nn.l2_normalize(vlad, axis=1)\n\n        vlad = tf.matmul(vlad, self.hidden1_weights)\n\n        if self.gating:\n            vlad = PoolingBaseModel.context_gating(vlad)\n\n        return vlad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using ResNET Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs NetVLAD Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_netvlad_resnet = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_NetVLAD_Pool_ResNET')\n\n# Add a reshaping layer\nmodel_netvlad_resnet.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using NetVLAD: (without gating, batch normalization, is_training)\nmodel_netvlad_resnet.add(NetVLAD(feature_size=512, max_samples=1, cluster_size=64, output_dim=512, gating = False, add_batch_norm = False, is_training = False))\n\n# Flattening the pooled features\nmodel_netvlad_resnet.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_netvlad_resnet.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_netvlad_resnet.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_netvlad_resnet.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_netvlad_resnet.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_netvlad_resnet.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_netvlad_resnet.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_netvlad_resnet.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_netvlad_resnet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_netvlad_resnet,to_file='model_netvlad_resnet.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_resnet = tf.reshape(X_train_resnet, [X_train_resnet.shape[0], 1, X_train_resnet.shape[1]])\nX_valid_reshape_resnet = tf.reshape(X_valid_resnet, [X_valid_resnet.shape[0], 1, X_valid_resnet.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_netvlad_resnet = model_netvlad_resnet.fit(X_train_reshape_resnet,\n          Y_train_resnet,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_resnet, Y_valid_resnet),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using ResNET Approach - NetVLAD Pooling) :\\n------------------------------------\")\nX_test_reshape_resnet = tf.reshape(X_test_resnet, [X_test_resnet.shape[0], 1,X_test_resnet.shape[1]])\nmodel_netvlad_resnet.evaluate(X_test_reshape_resnet,Y_test_resnet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_netvlad_resnet.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_netvlad_resnet.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using ResNET Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_netvlad_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_netvlad_resnet.history['loss'],'r-o', label = 'train')\nplt.plot(history_netvlad_resnet.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using ResNET Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_netvlad_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_resnet_netvlad = model_netvlad_resnet.predict(X_test_resnet)\nY_pred_resnet_netvlad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_resnet_netvlad_round2 = Y_pred_resnet_netvlad.round(decimals=2)\nY_pred_resnet_netvlad_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_resnet_netvlad_round0 = Y_pred_resnet_netvlad.round(decimals=0)\nY_pred_resnet_netvlad_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using ResNET Approach - NetVLAD Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_resnet, Y_pred_resnet_netvlad_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_resnet, Y_pred_resnet_netvlad_round0))\nprint('Precision Score : ',(precision_score(Y_test_resnet, Y_pred_resnet_netvlad_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_resnet, Y_pred_resnet_netvlad_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_resnet, Y_pred_resnet_netvlad_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_resnet, Y_pred_resnet_netvlad_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_resnet_netvlad = confusion_matrix(Y_test_resnet, Y_pred_resnet_netvlad_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_resnet_netvlad, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using ResNET Approach - NetVLAD Pooling\", loc='center')\nplt.savefig(\"cm_netvlad_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_resnet_netvlad, tpr_resnet_netvlad, tr_resnet_netvlad = roc_curve(Y_test_resnet, np.array(Y_pred_resnet_netvlad_round2))\nauc_resnet_netvlad = roc_auc_score(Y_test_resnet, Y_pred_resnet_netvlad_round2)\n\nplt.plot(fpr_resnet_netvlad, tpr_resnet_netvlad, 'b-o', label = 'AUC = %0.4f'%auc_resnet_netvlad)\nplt.plot(fpr_resnet_netvlad,fpr_resnet_netvlad,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using ResNET Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_netvlad_resnet.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using C3D Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs NetVLAD Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_netvlad_c3d = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_NetVLAD_Pool_C3D')\n\n# Add a reshaping layer\nmodel_netvlad_c3d.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using NetVLAD: (without gating, batch normalization, is_training)\nmodel_netvlad_c3d.add(NetVLAD(feature_size=512, max_samples=1, cluster_size=64, output_dim=512, gating = False, add_batch_norm = False, is_training = False))\n\n# Flattening the pooled features\nmodel_netvlad_c3d.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_netvlad_c3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_netvlad_c3d.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_netvlad_c3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_netvlad_c3d.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_netvlad_c3d.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_netvlad_c3d.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_netvlad_c3d.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_netvlad_c3d.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_netvlad_c3d,to_file='model_netvlad_c3d.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_c3d = tf.reshape(X_train_c3d, [X_train_c3d.shape[0], 1, X_train_c3d.shape[1]])\nX_valid_reshape_c3d = tf.reshape(X_valid_c3d, [X_valid_c3d.shape[0], 1, X_valid_c3d.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_netvlad_c3d = model_netvlad_c3d.fit(X_train_reshape_c3d,\n          Y_train_c3d,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_c3d, Y_valid_c3d),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using C3D Approach - NetVLAD Pooling) :\\n------------------------------------\")\nX_test_reshape_c3d = tf.reshape(X_test_c3d, [X_test_c3d.shape[0], 1,X_test_c3d.shape[1]])\nmodel_netvlad_c3d.evaluate(X_test_reshape_c3d,Y_test_c3d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_netvlad_c3d.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_netvlad_c3d.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using C3D Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_netvlad_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_netvlad_c3d.history['loss'],'r-o', label = 'train')\nplt.plot(history_netvlad_c3d.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using C3D Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_netvlad_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_c3d_netvlad = model_netvlad_c3d.predict(X_test_c3d)\nY_pred_c3d_netvlad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_c3d_netvlad_round2 = Y_pred_c3d_netvlad.round(decimals=2)\nY_pred_c3d_netvlad_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_c3d_netvlad_round0 = Y_pred_c3d_netvlad.round(decimals=0)\nY_pred_c3d_netvlad_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using C3D Approach - NetVLAD Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_c3d, Y_pred_c3d_netvlad_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_c3d, Y_pred_c3d_netvlad_round0))\nprint('Precision Score : ',(precision_score(Y_test_c3d, Y_pred_c3d_netvlad_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_c3d, Y_pred_c3d_netvlad_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_c3d, Y_pred_c3d_netvlad_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_c3d, Y_pred_c3d_netvlad_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_c3d_netvlad = confusion_matrix(Y_test_c3d, Y_pred_c3d_netvlad_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_c3d_netvlad, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using C3D Approach - NetVLAD Pooling\", loc='center')\nplt.savefig(\"cm_netvlad_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_c3d_netvlad, tpr_c3d_netvlad, tr_c3d_netvlad = roc_curve(Y_test_c3d, np.array(Y_pred_c3d_netvlad_round2))\nauc_c3d_netvlad = roc_auc_score(Y_test_c3d, Y_pred_c3d_netvlad_round2)\n\nplt.plot(fpr_c3d_netvlad, tpr_c3d_netvlad, 'b-o', label = 'AUC = %0.4f'%auc_c3d_netvlad)\nplt.plot(fpr_c3d_netvlad,fpr_c3d_netvlad,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using C3D Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_netvlad_c3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using I3D Approach\n# Step - 5: Designing the Deep Learning Model.\n### Step - 5a: Design a model that performs NetVLAD Pooling.\n### Step - 5b: After this pooling layer, stack a fuly connected layer with a dropout layer (having 60% probability) that predicts whether in a frame action is happening or not.\n### Step - 5c : Compile the model and print the model summary.","metadata":{}},{"cell_type":"code","source":"# Number of classes in the target variable\nNB_CLASSES=1\n\n# Create a sequencial model in Keras\nmodel_netvlad_i3d = tf.keras.models.Sequential(name = 'Deep_Neural_Network_Model_NetVLAD_Pool_I3D')\n\n# Add a reshaping layer\nmodel_netvlad_i3d.add(tf.keras.layers.Reshape((1, 512),name = 'Reshaping'))\n          \n# Pooling using NetVLAD: (without gating, batch normalization, is_training)\nmodel_netvlad_i3d.add(NetVLAD(feature_size=512, max_samples=1, cluster_size=64, output_dim=512, gating = False, add_batch_norm = False, is_training = False))\n\n# Flattening the pooled features\nmodel_netvlad_i3d.add(keras.layers.Flatten(name = 'Flatten-Layer'))\n\n# Add the first hidden layer\nmodel_netvlad_i3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-1', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the second hidden layer\nmodel_netvlad_i3d.add(keras.layers.Dense(500,                    #Number of hidden nodes\n                             name='Hidden-Layer-2', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Add the third hidden layer\nmodel_netvlad_i3d.add(keras.layers.Dense(200,                    #Number of hidden nodes\n                             kernel_regularizer = l2(0.01),\n                             name='Hidden-Layer-3', #Logical name\n                             activation='sigmoid'))    #activation function\n\n# Adding a Dropout layer of probability of 60%.\nmodel_netvlad_i3d.add(keras.layers.Dropout(0.6, name = 'Dropout-Layer'))\n\n# Add an Output layer with sigmoid activation\nmodel_netvlad_i3d.add(keras.layers.Dense(NB_CLASSES,\n                             name='Output-Layer',\n                             activation='sigmoid'))\n\n#Compile the model with loss & metrics\nmodel_netvlad_i3d.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\nmodel_netvlad_i3d.build(input_shape = (None,1,512))\n\n#Print the model meta-data\nmodel_netvlad_i3d.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Diagram of the Model Architecture\nkeras.utils.plot_model(model_netvlad_i3d,to_file='model_netvlad_i3d.png', show_shapes=True, show_layer_activations=True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5d: Train the model.","metadata":{}},{"cell_type":"code","source":"#Make it verbose so we can see the progress\nVERBOSE=1\n\n#Set Batch size\nBATCH_SIZE=120\n\n#Set number of epochs\nEPOCHS=25\n\nprint(\"\\nTraining Progress:\\n------------------------------------\")\n\n# Reshaping Train and Valid features so that it satisfies the fit function requirements. \nX_train_reshape_i3d = tf.reshape(X_train_i3d, [X_train_i3d.shape[0], 1, X_train_i3d.shape[1]])\nX_valid_reshape_i3d = tf.reshape(X_valid_i3d, [X_valid_i3d.shape[0], 1, X_valid_i3d.shape[1]])\n\n# Assigning weights to labels since there is an imbalanced in dataset labels.\n# This will avoid overfitting as well as the model would not be bias.\nweights_assigned = {0:1,1:892}\n\n#Fit the model. This will perform the entire training cycle, including\n#forward propagation, loss computation, backward propagation.\n#Execute for the specified batch sizes and epoch\n#Perform validation after each epoch.\n\nhistory_netvlad_i3d = model_netvlad_i3d.fit(X_train_reshape_i3d,\n          Y_train_i3d,\n          class_weight = weights_assigned,\n          batch_size=BATCH_SIZE,\n          epochs=EPOCHS,\n          validation_data = (X_valid_reshape_i3d, Y_valid_i3d),\n          verbose = VERBOSE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 5e : Evaluate the model.","metadata":{}},{"cell_type":"code","source":"#Evaluate the model against the test dataset and print results\nprint(\"\\nEvaluation against Test Dataset (Using I3D Approach - NetVLAD Pooling) :\\n------------------------------------\")\nX_test_reshape_i3d = tf.reshape(X_test_i3d, [X_test_i3d.shape[0], 1,X_test_i3d.shape[1]])\nmodel_netvlad_i3d.evaluate(X_test_reshape_i3d,Y_test_i3d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 6: Plot train and validation accuracy and loss curves for the choosen epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(history_netvlad_i3d.history['accuracy'],'r-o', label = 'train')\nplt.plot(history_netvlad_i3d.history['val_accuracy'],'b-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.suptitle(\"Train Accuracy vs Validation Accuracy\")\nplt.title(\"Using I3D Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"accuracy_netvlad_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_netvlad_i3d.history['loss'],'r-o', label = 'train')\nplt.plot(history_netvlad_i3d.history['val_loss'],'g-o', label = 'validation')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.suptitle(\"Train Loss vs Validation Loss\")\nplt.title(\"Using I3D Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"loss_netvlad_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 7: Perform prediction of labels from the test features.","metadata":{}},{"cell_type":"code","source":"Y_pred_i3d_netvlad = model_netvlad_i3d.predict(X_test_i3d)\nY_pred_i3d_netvlad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_i3d_netvlad_round2 = Y_pred_i3d_netvlad.round(decimals=2)\nY_pred_i3d_netvlad_round2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_i3d_netvlad_round0 = Y_pred_i3d_netvlad.round(decimals=0)\nY_pred_i3d_netvlad_round0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 8: Calculating important metrics.\n#### Confusion matrix, Classification report, Precision, Recall, F1 score, Accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"Using I3D Approach - NetVLAD Pooling\")\nprint(\"Classification Report:\")\nprint(classification_report(Y_test_i3d, Y_pred_i3d_netvlad_round0))\nprint(\"Confusion Matrix: \")\nprint(confusion_matrix(Y_test_i3d, Y_pred_i3d_netvlad_round0))\nprint('Precision Score : ',(precision_score(Y_test_i3d, Y_pred_i3d_netvlad_round0, average = 'macro')))\nprint('Recall Score : ',(recall_score(Y_test_i3d, Y_pred_i3d_netvlad_round0, average = 'macro')))\nprint('F-1 Score : ',(f1_score(Y_test_i3d, Y_pred_i3d_netvlad_round0, average = 'macro')))\nprint(\"Accuracy:\", accuracy_score(Y_test_i3d, Y_pred_i3d_netvlad_round0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step - 9: Plotting Confusion matrix, ROC curve, AUC score.","metadata":{}},{"cell_type":"code","source":"cm_i3d_netvlad = confusion_matrix(Y_test_i3d, Y_pred_i3d_netvlad_round0)\n\nplt.figure(figsize = (5,5))\nsns.heatmap(data = cm_i3d_netvlad, linewidths = .5, annot = True, cmap = 'Blues',fmt=\".0f\")\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')\nplt.suptitle('Confusion matrix',size = 15)\nplt.title(\"Using I3D Approach - NetVLAD Pooling\", loc='center')\nplt.savefig(\"cm_netvlad_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_i3d_netvlad, tpr_i3d_netvlad, tr_i3d_netvlad = roc_curve(Y_test_i3d, np.array(Y_pred_i3d_netvlad_round2))\nauc_i3d_netvlad = roc_auc_score(Y_test_i3d, Y_pred_i3d_netvlad_round2)\n\nplt.plot(fpr_i3d_netvlad, tpr_i3d_netvlad, 'b-o', label = 'AUC = %0.4f'%auc_i3d_netvlad)\nplt.plot(fpr_i3d_netvlad,fpr_i3d_netvlad,linestyle = '--',color = 'k')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.suptitle('ROC curve',size = 15)\nplt.title(\"Using I3D Approach - NetVLAD Pooling\", loc='center')\nplt.legend()\nplt.savefig(\"roc_auc_netvlad_i3d.png\",dpi = 96)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}